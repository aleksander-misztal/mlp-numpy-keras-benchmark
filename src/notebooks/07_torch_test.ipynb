{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '../'))  # Cofamy siÄ™ o dwa poziomy i wchodzimy do /src\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from pipelines.heart_disease_pipeline import build_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ce431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aleksander Misztal\\Desktop\\project\\perceptron-numpy-keras-torch-benchmark\\env\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aleksander Misztal\\Desktop\\project\\perceptron-numpy-keras-torch-benchmark\\env\\lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/heart.csv')\n",
    "\n",
    "# Split data into features and target (HeartDisease)\n",
    "X = df.drop(columns=['HeartDisease'])  # Features\n",
    "y = df['HeartDisease']  # Target variable\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.6, random_state=42)\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = build_pipeline()\n",
    "\n",
    "# Fit the pipeline on the training set\n",
    "X_train_processed = pipeline.fit_transform(X_train, y_train)\n",
    "\n",
    "# Transform the validation and test sets\n",
    "X_val_processed = pipeline.transform(X_val)\n",
    "X_test_processed = pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cdf913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150, Loss: 0.6298\n",
      "Epoch 20/150, Loss: 0.6241\n",
      "Epoch 30/150, Loss: 0.5914\n",
      "Epoch 40/150, Loss: 0.5818\n",
      "Epoch 50/150, Loss: 0.5573\n",
      "Epoch 60/150, Loss: 0.5275\n",
      "Epoch 70/150, Loss: 0.5582\n",
      "Epoch 80/150, Loss: 0.5626\n",
      "Epoch 90/150, Loss: 0.5603\n",
      "Epoch 100/150, Loss: 0.5587\n",
      "Epoch 110/150, Loss: 0.5129\n",
      "Epoch 120/150, Loss: 0.5631\n",
      "Epoch 130/150, Loss: 0.5283\n",
      "Epoch 140/150, Loss: 0.5538\n",
      "Epoch 150/150, Loss: 0.5475\n",
      "Test Accuracy: 0.8326\n",
      "Test ROC AUC: 0.9070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data as PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_processed.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_processed.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_processed.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define the MLP model in PyTorch\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "model = MLP(input_dim=X_train_processed.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 150\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_prob = model(X_test_tensor).numpy().flatten()\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Results\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test ROC AUC: {test_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190680a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
